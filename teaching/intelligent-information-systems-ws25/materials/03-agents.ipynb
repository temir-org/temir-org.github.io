{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828cec7d-d98e-49fd-869b-e9ba1368ca6d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": "# Session 03: Intro to LLM Agents"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optional: install dependencies\n",
    "#!pip install openai-agents"
   ],
   "id": "9553c8c4533ee36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def mdprint(text):\n",
    "    \"\"\"Helper function for printing markdown text.\"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "def pprint(result):\n",
    "    \"\"\"Helper function for pretty-printing raw model responses.\"\"\"\n",
    "    for item in result.new_items:\n",
    "        print(item.__class__, json.dumps(item.to_input_item(), indent=2))"
   ],
   "id": "9b8c646dc3543de5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "API_URL = \"https://api.helmholtz-blablador.fz-juelich.de/v1/\"\n",
    "#API_KEY = \"<KEY>\"\n",
    "API_MODEL = \"1 - GPT-OSS-120b - an open model released by OpenAI in August 2025\" # Best for fast dev runs"
   ],
   "id": "7726fbb122569fe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from agents import AsyncOpenAI, set_tracing_disabled, OpenAIChatCompletionsModel, Agent, Runner, ModelSettings\n",
    "from openai.types.shared import Reasoning\n",
    "# Disable the tracing feature\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "# Instantiate the model with custom endpoint\n",
    "model = OpenAIChatCompletionsModel(\n",
    "    model=API_MODEL,\n",
    "    openai_client=AsyncOpenAI(api_key=API_KEY, base_url=API_URL)\n",
    ")"
   ],
   "id": "ced0e57097f49a56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base Agent\n",
    "\n",
    "The most basic agent is just an LLM call, without any further specifications."
   ],
   "id": "bd14cc100db32198"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "input = \"Whats the weather like in Kassel?\"",
   "id": "6921fbf624225eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_agent = Agent(\n",
    "    name=\"base_agent\",\n",
    "    model=model,\n",
    "    model_settings=ModelSettings(\n",
    "        reasoning=Reasoning(effort=\"low\")\n",
    "    )\n",
    ")\n",
    "base_result = await Runner.run(base_agent, input=input)"
   ],
   "id": "9d125625042089e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mdprint(base_result.final_output)",
   "id": "1683c02f8dd464b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reasoning Agent\n",
    "\n",
    "The base agent can be improved upon by enabling it to reason; it will usually provide better responses by allowing it to \"think before answering\"."
   ],
   "id": "5d2befd85c55dabc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reasoning_agent = Agent(\n",
    "    name=\"base_agent\",\n",
    "    model=model,\n",
    "    model_settings=ModelSettings(\n",
    "        reasoning=Reasoning(effort=\"high\")\n",
    "    )\n",
    ")\n",
    "reasoning_result = await Runner.run(reasoning_agent, input=input)"
   ],
   "id": "e1660f86595043ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mdprint(reasoning_result.final_output)\n",
    "#pprint(result)"
   ],
   "id": "e0bbed289b8eb1d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:16:30.566509Z",
     "start_time": "2025-11-13T10:16:30.561371Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### Tool Use\n",
    "\n",
    "As we have seen before, LLMs could greatly benefit from being able to interact with the world to, for example, retrieve up-to-date data. This is achieved through *tools*.\n",
    "\n",
    "Lets implement a basic weather information tool, based on the `wttr.in` API."
   ],
   "id": "b5f0a9d81fa9375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!curl 'wttr.in/Kassel?format=j1'",
   "id": "5a58421bdf4aa25f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from typing import Any\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> dict[str, Any]:\n",
    "    \"\"\"Retrieves the weather forecast for a specified location.\"\"\"\n",
    "    return requests.get(f\"http://wttr.in/{city}?format=j1\").json()\n"
   ],
   "id": "fa10dab2eba4ffb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tool_agent = Agent(\n",
    "    name=\"tool_agent\",\n",
    "    model=model,\n",
    "    instructions=\"Always use the provided tools to solve the task given by the user. Provide very succint answers.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "tool_result = await Runner.run(tool_agent, input=input)"
   ],
   "id": "44a4a6c94b891ef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mdprint(tool_result.final_output)",
   "id": "3a47b58708a7f171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result = await Runner.run(tool_agent, input=\"Do i need a jacket when going outside in Kassel?\")",
   "id": "69f4292cdad054a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mdprint(result.final_output)",
   "id": "e336c22d971b829d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Structured Outputs\n",
    "\n",
    "For many workflows, it is helpful to have agents return their response in a structured format (most commonly JSON), to be able to parse it into a python data structure and interface with program flow. The `agents` package uses `pydantic` for data modeling internally, so we will opt for that as well.\n",
    "\n",
    "**Note**: due to API limitations, we cannot use the `output_type` parameter of the `Agent` class directly, but have to emulate its behaviour through explicit prompting.\n",
    "\n",
    "Let's implement a basic `Feedback` data model, consisting of a written feedback and a score enum, that we can use to control program flow later:"
   ],
   "id": "4a09f69572dd7968"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This is for casting output types to a JSON schema we can supply to the model.\n",
    "from pydantic.dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "@dataclass\n",
    "class Feedback:\n",
    "    feedback: str\n",
    "    score: Literal[\"pass\", \"needs_improvement\", \"fail\"]"
   ],
   "id": "bb204eae6c00fc7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pydantic also provides a handy way to generate an explicit JSON schema that models should conform to:",
   "id": "e817c807309eb20d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydantic import TypeAdapter\n",
    "\n",
    "TypeAdapter(Feedback).json_schema()"
   ],
   "id": "ede24e3dee0a3940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### LLM-as-a-judge (Adaptive Loops)\n",
    "\n",
    "We can extend our agent workflow to include multiple agents in multiple roles. For example, consider a story writing task with two agents, with the following flow:\n",
    "- The first agent generates an outline for a story\n",
    "- The second agent judges the outline and provides feedback\n",
    "- We loop until the judge is satisfied with the outline\n",
    "\n",
    "Here, the structured output defined previously is needed: we can use the `score` property of the judges' output to either continue refining, or exit.\n",
    "\n",
    "**Note**: pay attention to cap the number of iterations, either by prompting or with a hard limit. Its easy to get stuck in an infinite feedback loop otherwise!"
   ],
   "id": "f27afea6a6e48334"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "story_outline_generator = Agent(\n",
    "    name=\"story_outline_generator\",\n",
    "    instructions=(\n",
    "        \"You generate a very short story outline based on the user's input. \"\n",
    "        \"Do not write a full story, just the outline. \"\n",
    "        \"If there is any feedback provided, use it to improve the outline.\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "\n",
    "evaluator = Agent(\n",
    "    name=\"evaluator\",\n",
    "    instructions=(\n",
    "        \"You evaluate a story outline and decide if it's good enough. \"\n",
    "        \"If it's not good enough, you provide feedback on what needs to be improved. \"\n",
    "        \"Never give it a pass on the first try. \"\n",
    "        \"After 5 attempts, you can give it a pass if the story outline is good enough - do not go for perfection. \"\n",
    "        \"Reply in the given structured format, conforming exactly to its specification: \"\n",
    "        f\"{TypeAdapter(Feedback).json_schema()}\"\n",
    "    ),\n",
    "    model=model\n",
    ")"
   ],
   "id": "87434d3d6d21b6d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_items = [{\"content\": \"A story about a rainy afternoon in Kassel.\", \"role\": \"user\"}]\n",
    "outlines = []\n",
    "feedbacks = []\n",
    "\n",
    "while True:\n",
    "    story_outline_result = await Runner.run(story_outline_generator, input_items)\n",
    "    input_items = story_outline_result.to_input_list()\n",
    "    outlines.append(story_outline_result.final_output)\n",
    "\n",
    "    evaluator_result = await Runner.run(evaluator, input_items)\n",
    "    result = Feedback(**json.loads(evaluator_result.final_output)) # Cast raw response to feedback dataclass\n",
    "    feedbacks.append(result.feedback)\n",
    "\n",
    "    print(f\"Evaluator score: {result.score}\")\n",
    "\n",
    "    if result.score == \"pass\":\n",
    "        print(\"Story outline is good enough, exiting.\")\n",
    "        break\n",
    "\n",
    "    print(\"Re-running with feedback\")\n",
    "\n",
    "    input_items.append({\"content\": f\"Feedback: {result.feedback}\", \"role\": \"user\"})"
   ],
   "id": "623e846230b2b65c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mdprint(feedbacks[0])",
   "id": "bd0f4bbaf19ac463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Agents-as-tools\n",
    "\n",
    "We have already considered basic programmatic tools. However, we extend on that and call other agents for tools, to delegate tasks from a main coordinating agent. This is as simple as calling the `.as_tool` function of an agent, and passing it to the main agent."
   ],
   "id": "7cf14f722b7b70bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "german_agent = Agent(\n",
    "    name=\"german_agent\",\n",
    "    instructions=\"You translate the user's message to German\",\n",
    "    handoff_description=\"An english to german translator\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You translate the user's message to French\",\n",
    "    handoff_description=\"An english to french translator\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "italian_agent = Agent(\n",
    "    name=\"italian_agent\",\n",
    "    instructions=\"You translate the user's message to Italian\",\n",
    "    handoff_description=\"An english to italian translator\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools in order.\"\n",
    "        \"You never translate on your own, you always use the provided tools.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        german_agent.as_tool(\n",
    "            tool_name=\"translate_to_german\",\n",
    "            tool_description=\"Translate the user's message to German\",\n",
    "        ),\n",
    "        french_agent.as_tool(\n",
    "            tool_name=\"translate_to_french\",\n",
    "            tool_description=\"Translate the user's message to French\",\n",
    "        ),\n",
    "        italian_agent.as_tool(\n",
    "            tool_name=\"translate_to_italian\",\n",
    "            tool_description=\"Translate the user's message to Italian\",\n",
    "        ),\n",
    "    ],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "synthesizer_agent = Agent(\n",
    "    name=\"synthesizer_agent\",\n",
    "    instructions=\"You inspect translations, correct them if needed, and produce a final concatenated response.\",\n",
    "    model=model\n",
    ")"
   ],
   "id": "291fc577d471dbba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msg = \"Translate 'It's raining cats and dogs in Kassel.' to german and french.\"\n",
    "\n",
    "orchestrator_result = await Runner.run(orchestrator_agent, msg)\n",
    "synthesizer_result = await Runner.run(synthesizer_agent, orchestrator_result.to_input_list())\n",
    "\n",
    "mdprint(synthesizer_result.final_output)\n"
   ],
   "id": "204937fb71f83f25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Triage Agents & Handoff\n",
    "\n",
    "Agents-as-tools have a limited flow: a main agent calls another, which returns a result, and control flow resumes to the main agent. If we want the called agent to continue as the main, we can instead implement a *triage* pattern, where agents can hand off tasks to one another, and then have the called agent continue with the main conversation without returning control."
   ],
   "id": "97aeadf6098b84e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "german_agent = Agent(\n",
    "    name=\"german_agent\",\n",
    "    instructions=\"You only speak German\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[german_agent, spanish_agent, english_agent],\n",
    "    model=model\n",
    ")"
   ],
   "id": "ed307e375ee5ff6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msg = \"Hi, i would like know more about your return policy.\"\n",
    "triage_result = await Runner.run(triage_agent, msg)\n",
    "mdprint(triage_result.final_output)"
   ],
   "id": "fb53497a2d64177d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msg = \"Guten Tag, ich würde gern wissen wie ich eine Rücksendung erstelle.\"\n",
    "triage_result = await Runner.run(triage_agent, msg)\n",
    "mdprint(triage_result.final_output)"
   ],
   "id": "23e7fd6398588dfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "triage_result",
   "id": "6359a695d0a982d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Guardrails\n",
    "\n",
    "Guardrails are checks that run in parallel to the agent's execution. We discern between input guardrails and output guardrails.\n",
    "\n",
    "Input guardrails are used to, for example:\n",
    "- Check if input messages are off-topic\n",
    "- Check that input messages don't violate any policies\n",
    "- Take over control of the agent's execution if an unexpected input is detected\n",
    "\n",
    "Output guardrails are used to, for example:\n",
    "- Check if the output contains sensitive data\n",
    "- Check if the output is a valid response to the user's message"
   ],
   "id": "47449838cbefe8b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class GuardrailCriterion:\n",
    "    reasoning: str\n",
    "    trigger: bool"
   ],
   "id": "d62c9cf969148e38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from agents import input_guardrail, GuardrailFunctionOutput\n",
    "\n",
    "input_guardrail_agent = Agent(\n",
    "    name=\"Guardrail check\",\n",
    "    instructions=(\n",
    "        \"Check if the user is asking you to do their math homework.\"\n",
    "        \"Reply in the given structured format, conforming exactly to its specification: \"\n",
    "        f\"{TypeAdapter(GuardrailCriterion).json_schema()}\"\n",
    "    ),\n",
    "    model=model\n",
    ")\n",
    "\n",
    "@input_guardrail\n",
    "async def math_guardrail(context, agent, input):\n",
    "    \"\"\"This is an input guardrail function, which happens to call an agent to check if the input\n",
    "    is a math homework question.\n",
    "    \"\"\"\n",
    "    result = await Runner.run(input_guardrail_agent, input, context=context.context)\n",
    "    criterion = GuardrailCriterion(**json.loads(result.final_output))\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=criterion.reasoning,\n",
    "        tripwire_triggered=criterion.trigger\n",
    "    )"
   ],
   "id": "dafc9580d4b0478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from agents import output_guardrail\n",
    "\n",
    "@output_guardrail\n",
    "async def sensitive_data_check(context, agent, output):\n",
    "    phone_number_in_response = \"+49\" in output\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=\"Phone number in response!\",\n",
    "        tripwire_triggered=phone_number_in_response,\n",
    "    )"
   ],
   "id": "f1178e474913815c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from agents import InputGuardrailTripwireTriggered, OutputGuardrailTripwireTriggered\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Friendly agent\",\n",
    "    instructions=\"You are a friendly helpful agent, eager to help the user with whatever they request.\",\n",
    "    input_guardrails=[math_guardrail],\n",
    "    output_guardrails=[sensitive_data_check],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "async def call(prompt):\n",
    "    try:\n",
    "        result = await Runner.run(agent, prompt)\n",
    "        print(result.final_output)\n",
    "    except InputGuardrailTripwireTriggered:\n",
    "        print(\"Sorry, I can't help you with your math homework.\")\n",
    "    except OutputGuardrailTripwireTriggered:\n",
    "        print(\"Sorry, I can't provide you with sensitive data.\")"
   ],
   "id": "3d9a591c44ec7362",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "await call(\"Please solve this equation for x: 4x^2 + 2x = 19\")",
   "id": "e132f82d64578bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "await call(\"Can you give me the phone number of the university of kassel?\")",
   "id": "637d609c5e15f804",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
